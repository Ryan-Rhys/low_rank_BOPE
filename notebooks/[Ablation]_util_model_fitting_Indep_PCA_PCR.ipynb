{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "code_folding": [],
        "customInput": null,
        "hidden_ranges": [],
        "originalKey": "c2748393-d4ea-4830-94f2-145dc2fb0c14",
        "showInput": false
      },
      "source": [
        "# Overview\n",
        "\n",
        "In this notebook, we generate synthetic low-rank outcome data and test different ways of learning the utility model:\n",
        "- fit indepdendent GPs to each outcome\n",
        "- learn a PCA decomposition, fit independent GPs to the top principal components that explain most variance\n",
        "- learn a PCA decomposition, select top PCs that explain the utility, fit independent GPs to them\n",
        "\n",
        "Look at two test cases here:\n",
        "- outcome dimensionality = 20, rank = 1\n",
        "- outcome dimensionality = 20, rank = 2; utility depends on the less dominant axis\n",
        "\n",
        "Test case 1 helps us answer the question: Does PCA do better than Indep? Is it because it's easier to learn the PCA matrix than the independent GP hyperparameters?\n",
        "\n",
        "Test case 2 helps us compare PCA and PCR. We expect PCR to do better than PCA in this case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "code_folding": [],
        "collapsed": false,
        "customOutput": null,
        "executionStartTime": 1673017165515,
        "executionStopTime": 1673017169427,
        "hidden_ranges": [],
        "originalKey": "ed006d17-14ef-41a2-9b4f-6163953a6ec9",
        "requestMsgId": "c593f2fe-2fb2-4595-9412-d4a68b8971a6",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/yz685/anaconda3/envs/bope_pca/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os, sys\n",
        "# file_dir = os.path.dirname(__file__)\n",
        "# sys.path.append(file_dir)\n",
        "sys.path.append('/home/yz685/low_rank_BOPE')\n",
        "sys.path.append('/home/yz685/low_rank_BOPE/low_rank_BOPE')\n",
        "import warnings\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.linalg\n",
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "from test_problems.synthetic_problem import generate_principal_axes, PCATestProblem\n",
        "from src.transforms import (\n",
        "    generate_random_projection,\n",
        "    InputCenter,\n",
        "    LinearProjectionInputTransform,\n",
        "    LinearProjectionOutcomeTransform,\n",
        "    PCAInputTransform,\n",
        "    PCAOutcomeTransform,\n",
        "    SubsetOutcomeTransform,\n",
        ")\n",
        "from src.pref_learning_helpers import gen_initial_real_data, fit_pref_model\n",
        "from src.diagnostics import check_util_model_fit\n",
        "from src.models import make_modified_kernel\n",
        "\n",
        "# import botorch, gpytorch functions\n",
        "from botorch import fit_gpytorch_model, fit_gpytorch_mll\n",
        "from botorch.optim.fit import fit_gpytorch_scipy\n",
        "from botorch.optim.utils import _filter_kwargs\n",
        "from botorch.utils.sampling import draw_sobol_samples\n",
        "from botorch.models import SingleTaskGP\n",
        "from botorch.models.transforms.outcome import ChainedOutcomeTransform, Standardize\n",
        "from botorch.models.transforms.input import (\n",
        "    ChainedInputTransform,\n",
        "    FilterFeatures,\n",
        "    Normalize,\n",
        ")\n",
        "\n",
        "from gpytorch.kernels import MaternKernel\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from gpytorch.likelihoods import GaussianLikelihood\n",
        "from gpytorch.priors import GammaPrior\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "tkwargs = {\n",
        "    \"dtype\": torch.double,\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test case 1: outcome dimensionality = 20, rank = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "code_folding": [],
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStopTime": 1654062966426,
        "hidden_ranges": [],
        "originalKey": "61a998be-17b2-430a-bb83-f540b1c4ae41",
        "requestMsgId": "61a998be-17b2-430a-bb83-f540b1c4ae41",
        "showInput": true
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"input_dim\": 1,\n",
        "    \"outcome_dim\": 20,\n",
        "    \"latent_dim\": 1,\n",
        "    \"PC_noise_level\": 0,\n",
        "    \"noise_std\": 0.1,\n",
        "    \"num_initial_samples\": 20,\n",
        "    \"num_sample_points\": 30,\n",
        "    \"jitter\": 0.00001,  # noqa\n",
        "    \"ground_truth_principal_axes\": torch.Tensor([1]*20),\n",
        "    \"PC_lengthscales\": [0.1],\n",
        "    \"PC_scaling_factors\": [2],\n",
        "    \"variance_explained_threshold\": 0.99,\n",
        "}\n",
        "\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "ground_truth_principal_axes = config['ground_truth_principal_axes'].unsqueeze(0)\n",
        "\n",
        "initial_X = torch.randn((config[\"num_initial_samples\"], config[\"input_dim\"]), **tkwargs)\n",
        "\n",
        "obj_indices = list(range(config[\"outcome_dim\"]))\n",
        "cons_indices = []\n",
        "\n",
        "problem = PCATestProblem(\n",
        "    opt_config=(obj_indices, cons_indices),\n",
        "    initial_X=initial_X,\n",
        "    bounds=torch.Tensor([[0, 1]] * config[\"input_dim\"]),\n",
        "    ground_truth_principal_axes=ground_truth_principal_axes,\n",
        "    noise_std=config[\"noise_std\"],\n",
        "    PC_lengthscales=Tensor(config[\"PC_lengthscales\"]),\n",
        "    PC_scaling_factors=Tensor(config[\"PC_scaling_factors\"]),\n",
        "    dtype=torch.double,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LinearUtil(torch.nn.Module):\n",
        "    def __init__(self, beta: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            beta: size `output_dim` tensor\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.register_buffer(\"beta\", beta)\n",
        "\n",
        "    def calc_raw_util_per_dim(self, Y):\n",
        "        return Y * self.beta.to(Y)\n",
        "\n",
        "    def forward(self, Y, X=None):\n",
        "        return Y @ self.beta.to(Y)\n",
        "\n",
        "class SumOfSquaresUtil(torch.nn.Module):\n",
        "    def __init__(self, beta: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            beta: size `output_dim` tensor\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.register_buffer(\"beta\", beta)\n",
        "\n",
        "    def calc_raw_util_per_dim(self, Y):\n",
        "        return torch.square(Y) * self.beta.to(Y)\n",
        "\n",
        "    def forward(self, Y, X=None):\n",
        "        return torch.square(Y) @ self.beta.to(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "beta = torch.tensor([1]*config[\"outcome_dim\"], **tkwargs)\n",
        "util_func = LinearUtil(beta=beta)\n",
        "\n",
        "train_X, train_Y, util_vals, comps = gen_initial_real_data(n=100, problem=problem, util_func=util_func)\n",
        "\n",
        "# train_Y = train_Y - torch.mean(train_Y, dim = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([100, 1]), torch.Size([100, 20]))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_X.shape, train_Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ExactMarginalLogLikelihood(\n",
              "  (likelihood): GaussianLikelihood(\n",
              "    (noise_covar): HomoskedasticNoise(\n",
              "      (noise_prior): GammaPrior()\n",
              "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
              "    )\n",
              "  )\n",
              "  (model): SingleTaskGP(\n",
              "    (likelihood): GaussianLikelihood(\n",
              "      (noise_covar): HomoskedasticNoise(\n",
              "        (noise_prior): GammaPrior()\n",
              "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
              "      )\n",
              "    )\n",
              "    (mean_module): ConstantMean()\n",
              "    (covar_module): MaternKernel(\n",
              "      (lengthscale_prior): GammaPrior()\n",
              "      (raw_lengthscale_constraint): Positive()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "st_model = SingleTaskGP(\n",
        "    train_X,\n",
        "    train_Y,\n",
        "    covar_module = MaternKernel(lengthscale_prior = GammaPrior(3,6))\n",
        ")\n",
        "st_mll = ExactMarginalLogLikelihood(st_model.likelihood, st_model)\n",
        "fit_gpytorch_model(st_mll)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.2239, 0.2215, 0.2233, 0.2244, 0.2242, 0.2232, 0.2233, 0.2231, 0.2243,\n",
            "         0.2244, 0.2222, 0.2231, 0.2247, 0.2244, 0.2236, 0.2227, 0.2239, 0.2237,\n",
            "         0.2233, 0.2247]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "options = {\"maxiter\": 1000}\n",
        "\n",
        "pca_model = SingleTaskGP(\n",
        "    train_X,\n",
        "    train_Y,\n",
        "    outcome_transform=ChainedOutcomeTransform(\n",
        "        **{\n",
        "            \"standardize\": Standardize(config[\"outcome_dim\"], min_stdv=100),\n",
        "            \"pca\": PCAOutcomeTransform(num_axes=1),\n",
        "        }\n",
        "    ),\n",
        "    likelihood=GaussianLikelihood(noise_prior=GammaPrior(0.9, 10)),\n",
        ")\n",
        "pca_mll = ExactMarginalLogLikelihood(pca_model.likelihood, pca_model)\n",
        "\n",
        "fit_gpytorch_mll(pca_mll)\n",
        "\n",
        "print(pca_model.outcome_transform['pca'].axes_learned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 403,
      "metadata": {},
      "outputs": [],
      "source": [
        "def helper(num_test_points, models_dict, outcome_idxs):\n",
        "\n",
        "    test_X = torch.linspace(0, 1, num_test_points).unsqueeze(1).to(**tkwargs)\n",
        "    test_Y = problem.eval_metrics_true(test_X).detach()\n",
        "\n",
        "    for outcome_idx in outcome_idxs:\n",
        "\n",
        "        for model_name, model in models_dict.items():\n",
        "\n",
        "            test_Y_posterior_mean = model.posterior(test_X).mean[:, outcome_idx]\n",
        "           \n",
        "            print(model_name, 'outcome', outcome_idx, 'RMSE', torch.sqrt(torch.mean(torch.square(test_Y_posterior_mean - test_Y[:,outcome_idx]))).item())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca_axes_dict = {\n",
        "    \"learned\": pca_model.outcome_transform['pca'].axes_learned,\n",
        "    \"true\": ground_truth_principal_axes # TODO: normalize\n",
        "}\n",
        "# TODO: later, run regression and add PCR_axes_dict for the rank-2 test case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fit_util_models(train_Y, comps, util_vals, input_transform, covar_module):\n",
        "    util_model = fit_pref_model(\n",
        "        train_Y, \n",
        "        comps, \n",
        "        input_transform = input_transform, \n",
        "        covar_module = covar_module\n",
        "    )\n",
        "    util_model_oracle = SingleTaskGP(\n",
        "        train_Y, \n",
        "        util_vals.unsqueeze(1), \n",
        "        input_transform = input_transform, \n",
        "        covar_module = covar_module\n",
        "    )\n",
        "    mll = ExactMarginalLogLikelihood(util_model_oracle.likelihood, util_model_oracle)\n",
        "    fit_gpytorch_mll(mll)\n",
        "\n",
        "    return util_model, util_model_oracle\n",
        "\n",
        "def fit_models_helper(train_Y, comps, util_vals, method, axes_dict = None, modify_kernel = False):\n",
        "\n",
        "    input_transform = None\n",
        "    models_dict = {}\n",
        "    if method in (\"pca\", \"pcr\"):\n",
        "        for axes_label, axes in axes_dict.items():\n",
        "            latent_dim = axes.shape[0]\n",
        "            input_transform = ChainedInputTransform(\n",
        "                        **{\n",
        "                            \"center\": InputCenter(config[\"outcome_dim\"]),\n",
        "                            \"pca\": PCAInputTransform(axes.to(torch.double)),\n",
        "                        }\n",
        "                    )\n",
        "            covar_module = make_modified_kernel(ard_num_dims=latent_dim) if modify_kernel else None\n",
        "\n",
        "            util_model, util_model_oracle = fit_util_models(\n",
        "                train_Y, comps, util_vals, input_transform, covar_module)\n",
        "            models_dict[method+'_'+axes_label] = util_model\n",
        "            models_dict[method+'_'+axes_label+'_oracle'] = util_model_oracle\n",
        "    \n",
        "    elif method == \"st\":\n",
        "        covar_module = make_modified_kernel(ard_num_dims=train_Y.shape[-1]) if modify_kernel else None\n",
        "        input_transform = None\n",
        "        util_model, util_model_oracle = fit_util_models(\n",
        "                train_Y, comps, util_vals, input_transform, covar_module)\n",
        "        models_dict[method] = util_model\n",
        "        models_dict[method+'_oracle'] = util_model_oracle\n",
        "    \n",
        "    return models_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca_models_dict = fit_models_helper(\n",
        "    train_Y, comps, util_vals, \n",
        "    method=\"pca\", \n",
        "    axes_dict = pca_axes_dict, \n",
        "    modify_kernel = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['pca_learned', 'pca_learned_oracle', 'pca_true', 'pca_true_oracle'])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pca_models_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "st_models_dict = fit_models_helper(\n",
        "    train_Y, comps, util_vals, \n",
        "    method=\"st\", \n",
        "    # axes_dict = pca_axes_dict, \n",
        "    # modify_kernel = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['st', 'st_oracle'])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "st_models_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_util_model_fit_wrapper(models_dict, seed = 0):\n",
        "    torch.manual_seed(seed)\n",
        "    acc_dict = {}\n",
        "    for model_key, model in models_dict.items():\n",
        "        acc = check_util_model_fit(\n",
        "            pref_model = model,\n",
        "            problem = problem,\n",
        "            util_func = util_func,\n",
        "            n_test = 1000,\n",
        "            batch_eval = True,\n",
        "            return_util_vals = False\n",
        "        )\n",
        "        acc_dict[model_key] = acc\n",
        "    \n",
        "    return acc_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'pca_learned': 0.9660000205039978,\n",
              " 'pca_learned_oracle': 0.9380000233650208,\n",
              " 'pca_true': 0.9319999814033508,\n",
              " 'pca_true_oracle': 0.949999988079071}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "check_util_model_fit_wrapper(pca_models_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'st': 0.8899999856948853, 'st_oracle': 0.9879999756813049}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "check_util_model_fit_wrapper(st_models_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Next TODO:\n",
        "\n",
        "# look at nonlinear utility\n",
        "# math derivation\n",
        "# PCR"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test case 2: outcome dimensionality = 20, rank = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 438,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"input_dim\": 1,\n",
        "    \"outcome_dim\": 20,\n",
        "    \"latent_dim\": 1,\n",
        "    \"PC_noise_level\": 0,\n",
        "    \"noise_std\": 0.1,\n",
        "    \"num_initial_samples\": 20,\n",
        "    \"num_sample_points\": 30,\n",
        "    \"jitter\": 0.00001,  # noqa\n",
        "    \"ground_truth_principal_axes\": torch.Tensor([1]*20),\n",
        "    \"PC_lengthscales\": [0.1],\n",
        "    \"PC_scaling_factors\": [2],\n",
        "    \"variance_explained_threshold\": 0.99,\n",
        "}\n",
        "\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "ground_truth_principal_axes = config['ground_truth_principal_axes'].unsqueeze(0)\n",
        "\n",
        "initial_X = torch.randn((config[\"num_initial_samples\"], config[\"input_dim\"]), **tkwargs)\n",
        "\n",
        "obj_indices = list(range(config[\"outcome_dim\"]))\n",
        "cons_indices = []\n",
        "\n",
        "problem = PCATestProblem(\n",
        "    opt_config=(obj_indices, cons_indices),\n",
        "    initial_X=initial_X,\n",
        "    bounds=torch.Tensor([[0, 1]] * config[\"input_dim\"]),\n",
        "    ground_truth_principal_axes=ground_truth_principal_axes,\n",
        "    noise_std=config[\"noise_std\"],\n",
        "    PC_lengthscales=Tensor(config[\"PC_lengthscales\"]),\n",
        "    PC_scaling_factors=Tensor(config[\"PC_scaling_factors\"]),\n",
        "    dtype=torch.double,\n",
        ")\n",
        "\n",
        "use_modified_kernel = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 439,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "beta = torch.tensor([1]*config[\"outcome_dim\"], **tkwargs)\n",
        "util_func = LinearUtil(beta=beta)\n",
        "\n",
        "train_X, train_Y, util_vals, comps = gen_initial_real_data(n=100, problem=problem, util_func=util_func)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 440,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([100, 20]), torch.Size([100]), torch.Size([50, 2]))"
            ]
          },
          "execution_count": 440,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_Y.shape, util_vals.shape, comps.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 441,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ExactMarginalLogLikelihood(\n",
              "  (likelihood): GaussianLikelihood(\n",
              "    (noise_covar): HomoskedasticNoise(\n",
              "      (noise_prior): GammaPrior()\n",
              "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
              "    )\n",
              "  )\n",
              "  (model): SingleTaskGP(\n",
              "    (likelihood): GaussianLikelihood(\n",
              "      (noise_covar): HomoskedasticNoise(\n",
              "        (noise_prior): GammaPrior()\n",
              "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
              "      )\n",
              "    )\n",
              "    (mean_module): ConstantMean()\n",
              "    (covar_module): MaternKernel(\n",
              "      (lengthscale_prior): GammaPrior()\n",
              "      (raw_lengthscale_constraint): Positive()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 441,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "st_model_low = SingleTaskGP(\n",
        "    train_X,\n",
        "    train_Y,\n",
        "    covar_module = MaternKernel(lengthscale_prior = GammaPrior(3,6))\n",
        ")\n",
        "st_mll_low = ExactMarginalLogLikelihood(st_model_low.likelihood, st_model_low)\n",
        "fit_gpytorch_mll(st_mll_low)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 442,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.2239, 0.2215, 0.2233, 0.2244, 0.2242, 0.2232, 0.2233, 0.2231, 0.2243,\n",
            "         0.2244, 0.2222, 0.2231, 0.2247, 0.2244, 0.2236, 0.2227, 0.2239, 0.2237,\n",
            "         0.2233, 0.2247]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "options = {\"maxiter\": 1000}\n",
        "\n",
        "pca_model_low = SingleTaskGP(\n",
        "    train_X,\n",
        "    train_Y,\n",
        "    outcome_transform=ChainedOutcomeTransform(\n",
        "        **{\n",
        "            \"standardize\": Standardize(config[\"outcome_dim\"], min_stdv=100),\n",
        "            \"pca\": PCAOutcomeTransform(num_axes=1),\n",
        "        }\n",
        "    ),\n",
        "    likelihood=GaussianLikelihood(noise_prior=GammaPrior(0.9, 10)),\n",
        ")\n",
        "pca_mll_low = ExactMarginalLogLikelihood(pca_model_low.likelihood, pca_model_low)\n",
        "\n",
        "# train PCA model and log training stats\n",
        "# fit_gpytorch_scipy(pca_mll, options=options)\n",
        "fit_gpytorch_mll(pca_mll_low)\n",
        "\n",
        "print(pca_model_low.outcome_transform['pca'].axes_learned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 443,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ExactMarginalLogLikelihood(\n",
              "  (likelihood): GaussianLikelihood(\n",
              "    (noise_covar): HomoskedasticNoise(\n",
              "      (noise_prior): GammaPrior()\n",
              "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
              "    )\n",
              "  )\n",
              "  (model): SingleTaskGP(\n",
              "    (likelihood): GaussianLikelihood(\n",
              "      (noise_covar): HomoskedasticNoise(\n",
              "        (noise_prior): GammaPrior()\n",
              "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
              "      )\n",
              "    )\n",
              "    (mean_module): ConstantMean()\n",
              "    (covar_module): ScaleKernel(\n",
              "      (base_kernel): RBFKernel(\n",
              "        (lengthscale_prior): GammaPrior()\n",
              "        (raw_lengthscale_constraint): GreaterThan(1.000E-04)\n",
              "      )\n",
              "      (outputscale_prior): SmoothedBoxPrior()\n",
              "      (raw_outputscale_constraint): Interval(2.000E-01, 5.000E+00)\n",
              "    )\n",
              "    (input_transform): ChainedInputTransform(\n",
              "      (center): InputCenter()\n",
              "      (pca): PCAInputTransform()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 443,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "use_modified_kernel = True\n",
        "\n",
        "pca_covar_module = None\n",
        "if use_modified_kernel:\n",
        "    pca_covar_module = make_modified_kernel(ard_num_dims = 1)\n",
        "\n",
        "\n",
        "pca_util_model = fit_pref_model(\n",
        "    train_Y, \n",
        "    comps, \n",
        "    input_transform=ChainedInputTransform(\n",
        "                    **{\n",
        "                        \"center\": InputCenter(config[\"outcome_dim\"]),\n",
        "                        \"pca\": PCAInputTransform(pca_model_low.outcome_transform['pca'].axes_learned),\n",
        "                    }\n",
        "                ),\n",
        "    covar_module = pca_covar_module\n",
        ")\n",
        "\n",
        "pca_util_model_oracle = SingleTaskGP(\n",
        "    train_Y, \n",
        "    util_vals.unsqueeze(1), \n",
        "    input_transform=ChainedInputTransform(\n",
        "                    **{\n",
        "                        \"center\": InputCenter(config[\"outcome_dim\"]),\n",
        "                        \"pca\": PCAInputTransform(pca_model_low.outcome_transform['pca'].axes_learned),\n",
        "                    }\n",
        "                ),\n",
        "    covar_module = pca_covar_module\n",
        ")\n",
        "\n",
        "mll = ExactMarginalLogLikelihood(pca_util_model_oracle.likelihood, pca_util_model_oracle)\n",
        "fit_gpytorch_model(mll)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 450,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ExactMarginalLogLikelihood(\n",
              "  (likelihood): GaussianLikelihood(\n",
              "    (noise_covar): HomoskedasticNoise(\n",
              "      (noise_prior): GammaPrior()\n",
              "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
              "    )\n",
              "  )\n",
              "  (model): SingleTaskGP(\n",
              "    (likelihood): GaussianLikelihood(\n",
              "      (noise_covar): HomoskedasticNoise(\n",
              "        (noise_prior): GammaPrior()\n",
              "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
              "      )\n",
              "    )\n",
              "    (mean_module): ConstantMean()\n",
              "    (covar_module): ScaleKernel(\n",
              "      (base_kernel): RBFKernel(\n",
              "        (lengthscale_prior): GammaPrior()\n",
              "        (raw_lengthscale_constraint): GreaterThan(1.000E-04)\n",
              "      )\n",
              "      (outputscale_prior): SmoothedBoxPrior()\n",
              "      (raw_outputscale_constraint): Interval(2.000E-01, 5.000E+00)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 450,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "use_modified_kernel = True\n",
        "\n",
        "st_covar_module = None\n",
        "if use_modified_kernel:\n",
        "    st_covar_module = make_modified_kernel(ard_num_dims = 20)\n",
        "\n",
        "st_util_model = fit_pref_model(\n",
        "    train_Y, \n",
        "    comps, \n",
        "    # input_transform=Normalize(config[\"outcome_dim\"])\n",
        "    covar_module = st_covar_module\n",
        ")\n",
        "\n",
        "st_util_model_oracle = SingleTaskGP(\n",
        "    train_Y, \n",
        "    util_vals.unsqueeze(1), \n",
        "    covar_module = st_covar_module\n",
        ")\n",
        "\n",
        "mll = ExactMarginalLogLikelihood(st_util_model_oracle.likelihood, st_util_model_oracle)\n",
        "fit_gpytorch_model(mll)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 448,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pca util accuracy:  0.9660000205039978\n",
            "pca oracle util accuracy:  0.9380000233650208\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(0)\n",
        "test_util_vals_pca, pred_util_vals_pca, util_acc_pca = check_util_model_fit(\n",
        "    pref_model = pca_util_model,\n",
        "    problem=problem,\n",
        "    util_func=util_func,\n",
        "    n_test=1000,\n",
        "    batch_eval=True,\n",
        "    return_util_vals = True\n",
        ")\n",
        "print('pca util accuracy: ', util_acc_pca)\n",
        "\n",
        "test_util_vals_pca_oracle, pred_util_vals_pca_oracle, util_acc_pca_oracle = check_util_model_fit(\n",
        "    pref_model = pca_util_model_oracle,\n",
        "    problem=problem,\n",
        "    util_func=util_func,\n",
        "    n_test=1000,\n",
        "    batch_eval=True,\n",
        "    return_util_vals = True\n",
        ")\n",
        "print('pca oracle util accuracy: ', util_acc_pca_oracle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 451,
      "metadata": {},
      "outputs": [
        {
          "ename": "NotPSDError",
          "evalue": "Matrix not positive definite after repeatedly adding jitter up to 1.0e-01.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotPSDError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_742263/2557206449.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m test_util_vals_st, pred_util_vals_st, util_acc_st = check_util_model_fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mpref_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst_util_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mproblem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mutil_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutil_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/low_rank_BOPE/low_rank_BOPE/src/diagnostics.py\u001b[0m in \u001b[0;36mcheck_util_model_fit\u001b[0;34m(pref_model, problem, util_func, n_test, batch_eval, return_util_vals)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;31m# run pref_model on test data, get predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0mposterior_util_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpref_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0mposterior_util_mean_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposterior_util_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_test\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/bope_pca/lib/python3.9/site-packages/botorch/models/pairwise_gp.py\u001b[0m in \u001b[0;36mposterior\u001b[0;34m(self, X, output_indices, observation_noise, posterior_transform, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m             )\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m         \u001b[0mpost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0mposterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPyTorchPosterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mposterior_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/bope_pca/lib/python3.9/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/bope_pca/lib/python3.9/site-packages/botorch/models/pairwise_gp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, datapoints)\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# perform a cholesky decomposition to check and amend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             covariance_matrix=RootLinearOperator(\n\u001b[0;32m--> 857\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaled_psd_safe_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_covar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jitter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m             ),\n\u001b[1;32m    859\u001b[0m         )\n",
            "\u001b[0;32m~/anaconda3/envs/bope_pca/lib/python3.9/site-packages/botorch/models/pairwise_gp.py\u001b[0m in \u001b[0;36m_scaled_psd_safe_cholesky\u001b[0;34m(self, M, jitter)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovar_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mchol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsd_safe_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjitter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0mchol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mchol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/bope_pca/lib/python3.9/site-packages/linear_operator/utils/cholesky.py\u001b[0m in \u001b[0;36mpsd_safe_cholesky\u001b[0;34m(A, upper, out, jitter, max_tries)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mNumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mattempts\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mwith\u001b[0m \u001b[0msuccessively\u001b[0m \u001b[0mincreasing\u001b[0m \u001b[0mjitter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mto\u001b[0m \u001b[0mmake\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mraising\u001b[0m \u001b[0man\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \"\"\"\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_psd_safe_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjitter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_tries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/bope_pca/lib/python3.9/site-packages/linear_operator/utils/cholesky.py\u001b[0m in \u001b[0;36m_psd_safe_cholesky\u001b[0;34m(A, out, jitter, max_tries)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotPSDError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Matrix not positive definite after repeatedly adding jitter up to {jitter_new:.1e}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotPSDError\u001b[0m: Matrix not positive definite after repeatedly adding jitter up to 1.0e-01."
          ]
        }
      ],
      "source": [
        "torch.manual_seed(0)\n",
        "test_util_vals_st, pred_util_vals_st, util_acc_st = check_util_model_fit(\n",
        "    pref_model = st_util_model,\n",
        "    problem=problem,\n",
        "    util_func=util_func,\n",
        "    n_test=1000,\n",
        "    batch_eval=True,\n",
        "    return_util_vals = True\n",
        ")\n",
        "print('ST util accuracy: ', util_acc_st)\n",
        "\n",
        "test_util_vals_st_oracle, pred_util_vals_st_oracle, util_acc_st_oracle = check_util_model_fit(\n",
        "    pref_model = st_util_model_oracle,\n",
        "    problem=problem,\n",
        "    util_func=util_func,\n",
        "    n_test=1000,\n",
        "    batch_eval=True,\n",
        "    return_util_vals = True\n",
        ")\n",
        "print('st oracle util accuracy: ', util_acc_st_oracle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 377,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean difference in relative error of utility prediction -0.005132338271812821\n",
            "SD of difference in relative error of utility prediction 1.5979983156094808\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'difference in relative error of predicted test utility values')"
            ]
          },
          "execution_count": 377,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\n",
        "    'mean difference in relative error of utility prediction', \n",
        "    torch.mean((pred_util_vals_st_oracle - pred_util_vals_pca_oracle)/test_util_vals_st).item()\n",
        ")\n",
        "\n",
        "print(\n",
        "    'SD of difference in relative error of utility prediction', \n",
        "    torch.std((pred_util_vals_st_oracle - pred_util_vals_pca_oracle)/test_util_vals_st).item()\n",
        ")\n",
        "\n",
        "plt.hist(((pred_util_vals_st_oracle - pred_util_vals_pca_oracle)/test_util_vals_st).detach().numpy())\n",
        "plt.title('difference in relative error of predicted test utility values')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "bento_stylesheets": {
      "bento/extensions/flow/main.css": true,
      "bento/extensions/kernel_selector/main.css": true,
      "bento/extensions/kernel_ui/main.css": true,
      "bento/extensions/new_kernel/main.css": true,
      "bento/extensions/system_usage/main.css": true,
      "bento/extensions/theme/main.css": true
    },
    "captumWidgetMessage": {},
    "dataExplorerConfig": {},
    "disseminate_notebook_id": {
      "notebook_id": "310500951141609"
    },
    "disseminate_notebook_info": {
      "bento_version": "20220213-210538",
      "data_retention_policy": "default",
      "description": "",
      "hide_code": false,
      "hipster_group": "",
      "kernel_build_info": {
        "deps": [
          "//ae:notebook",
          "//ax/ax/utils/tutorials:tutorial_utils"
        ],
        "external_deps": [],
        "kernel_version": "1206"
      },
      "no_uii": true,
      "notebook_number": "1613503",
      "others_can_edit": false,
      "reviewers": "",
      "revision_id": "668025524236855",
      "tags": "",
      "tasks": "",
      "title": "QE_Lib_ae_ig_feed_recs_sourcing_quickbo_relax_media_age_analysis_b2"
    },
    "interpreter": {
      "hash": "f178f7686bb85c5c6e141a85fd4c17c3082d63b89f6cfaecdf98c22c0047a219"
    },
    "kernelspec": {
      "display_name": "Python 3.9.15 ('bope_pca')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "last_base_url": "https://devvm10848.prn0.facebook.com:8090/",
    "last_kernel_id": "33f76217-c3bb-4b3c-be64-89415980d364",
    "last_msg_id": "33163635-cf61d68d283ac2575827f13f_324",
    "last_server_session_id": "e5067c57-e1d5-4267-b323-2335fc1b1e29",
    "outputWidgetContext": {}
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
