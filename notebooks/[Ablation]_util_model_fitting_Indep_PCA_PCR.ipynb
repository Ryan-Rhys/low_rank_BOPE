{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "code_folding": [],
        "customInput": null,
        "hidden_ranges": [],
        "originalKey": "c2748393-d4ea-4830-94f2-145dc2fb0c14",
        "showInput": false
      },
      "source": [
        "# Overview\n",
        "\n",
        "In this notebook, we generate synthetic low-rank outcome data and test different ways of learning the utility model:\n",
        "- fit indepdendent GPs to each outcome\n",
        "- learn a PCA decomposition, fit independent GPs to the top principal components that explain most variance\n",
        "- learn a PCA decomposition, select top PCs that explain the utility, fit independent GPs to them\n",
        "\n",
        "Look at two test cases here:\n",
        "- outcome dimensionality = 20, rank = 1\n",
        "- outcome dimensionality = 20, rank = 2; utility depends on the less dominant axis\n",
        "\n",
        "Test case 1 helps us answer the question: Does PCA do better than Indep? Is it because it's easier to learn the PCA matrix than the independent GP hyperparameters?\n",
        "\n",
        "Test case 2 helps us compare PCA and PCR. We expect PCR to do better than PCA in this case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "code_folding": [],
        "collapsed": false,
        "customOutput": null,
        "executionStartTime": 1673017165515,
        "executionStopTime": 1673017169427,
        "hidden_ranges": [],
        "originalKey": "ed006d17-14ef-41a2-9b4f-6163953a6ec9",
        "requestMsgId": "c593f2fe-2fb2-4595-9412-d4a68b8971a6",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os, sys\n",
        "# file_dir = os.path.dirname(__file__)\n",
        "# sys.path.append(file_dir)\n",
        "sys.path.append('/home/yz685/low_rank_BOPE')\n",
        "sys.path.append('/home/yz685/low_rank_BOPE/low_rank_BOPE')\n",
        "import warnings\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.linalg\n",
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "from test_problems.synthetic_problem import generate_principal_axes, PCATestProblem\n",
        "from src.transforms import (\n",
        "    generate_random_projection,\n",
        "    InputCenter,\n",
        "    LinearProjectionInputTransform,\n",
        "    LinearProjectionOutcomeTransform,\n",
        "    PCAInputTransform,\n",
        "    PCAOutcomeTransform,\n",
        "    SubsetOutcomeTransform,\n",
        ")\n",
        "from src.pref_learning_helpers import gen_initial_real_data, fit_pref_model\n",
        "from src.diagnostics import check_util_model_fit\n",
        "from src.models import make_modified_kernel\n",
        "\n",
        "# import botorch, gpytorch functions\n",
        "from botorch import fit_gpytorch_model, fit_gpytorch_mll\n",
        "from botorch.optim.fit import fit_gpytorch_scipy\n",
        "from botorch.optim.utils import _filter_kwargs\n",
        "from botorch.utils.sampling import draw_sobol_samples\n",
        "from botorch.models import SingleTaskGP\n",
        "from botorch.models.transforms.outcome import ChainedOutcomeTransform, Standardize\n",
        "from botorch.models.transforms.input import (\n",
        "    ChainedInputTransform,\n",
        "    FilterFeatures,\n",
        "    Normalize,\n",
        ")\n",
        "\n",
        "from gpytorch.kernels import MaternKernel\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from gpytorch.likelihoods import GaussianLikelihood\n",
        "from gpytorch.priors import GammaPrior\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "tkwargs = {\n",
        "    \"dtype\": torch.double,\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test case 1: outcome dimensionality = 20, rank = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "code_folding": [],
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStopTime": 1654062966426,
        "hidden_ranges": [],
        "originalKey": "61a998be-17b2-430a-bb83-f540b1c4ae41",
        "requestMsgId": "61a998be-17b2-430a-bb83-f540b1c4ae41",
        "showInput": true
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"input_dim\": 1,\n",
        "    \"outcome_dim\": 20,\n",
        "    \"latent_dim\": 1,\n",
        "    \"PC_noise_level\": 0,\n",
        "    \"noise_std\": 0.1,\n",
        "    \"num_initial_samples\": 20,\n",
        "    \"num_sample_points\": 30,\n",
        "    \"jitter\": 0.00001,  # noqa\n",
        "    \"ground_truth_principal_axes\": torch.Tensor([1]*20),\n",
        "    \"PC_lengthscales\": [0.1],\n",
        "    \"PC_scaling_factors\": [2],\n",
        "    \"variance_explained_threshold\": 0.99,\n",
        "}\n",
        "\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "ground_truth_principal_axes = config['ground_truth_principal_axes'].unsqueeze(0)\n",
        "\n",
        "initial_X = torch.randn((config[\"num_initial_samples\"], config[\"input_dim\"]), **tkwargs)\n",
        "\n",
        "obj_indices = list(range(config[\"outcome_dim\"]))\n",
        "cons_indices = []\n",
        "\n",
        "problem = PCATestProblem(\n",
        "    opt_config=(obj_indices, cons_indices),\n",
        "    initial_X=initial_X,\n",
        "    bounds=torch.Tensor([[0, 1]] * config[\"input_dim\"]),\n",
        "    ground_truth_principal_axes=ground_truth_principal_axes,\n",
        "    noise_std=config[\"noise_std\"],\n",
        "    PC_lengthscales=Tensor(config[\"PC_lengthscales\"]),\n",
        "    PC_scaling_factors=Tensor(config[\"PC_scaling_factors\"]),\n",
        "    dtype=torch.double,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LinearUtil(torch.nn.Module):\n",
        "    def __init__(self, beta: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            beta: size `output_dim` tensor\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.register_buffer(\"beta\", beta)\n",
        "\n",
        "    def calc_raw_util_per_dim(self, Y):\n",
        "        return Y * self.beta.to(Y)\n",
        "\n",
        "    def forward(self, Y, X=None):\n",
        "        return Y @ self.beta.to(Y)\n",
        "\n",
        "class SumOfSquaresUtil(torch.nn.Module):\n",
        "    def __init__(self, beta: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            beta: size `output_dim` tensor\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.register_buffer(\"beta\", beta)\n",
        "\n",
        "    def calc_raw_util_per_dim(self, Y):\n",
        "        return torch.square(Y) * self.beta.to(Y)\n",
        "\n",
        "    def forward(self, Y, X=None):\n",
        "        return torch.square(Y) @ self.beta.to(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "beta = torch.tensor([1]*config[\"outcome_dim\"], **tkwargs)\n",
        "util_func = LinearUtil(beta=beta)\n",
        "\n",
        "train_X, train_Y, util_vals, comps = gen_initial_real_data(n=100, problem=problem, util_func=util_func)\n",
        "\n",
        "# train_Y = train_Y - torch.mean(train_Y, dim = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([100, 1]), torch.Size([100, 20]))"
            ]
          },
          "execution_count": 178,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_X.shape, train_Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ExactMarginalLogLikelihood(\n",
              "  (likelihood): GaussianLikelihood(\n",
              "    (noise_covar): HomoskedasticNoise(\n",
              "      (noise_prior): GammaPrior()\n",
              "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
              "    )\n",
              "  )\n",
              "  (model): SingleTaskGP(\n",
              "    (likelihood): GaussianLikelihood(\n",
              "      (noise_covar): HomoskedasticNoise(\n",
              "        (noise_prior): GammaPrior()\n",
              "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
              "      )\n",
              "    )\n",
              "    (mean_module): ConstantMean()\n",
              "    (covar_module): MaternKernel(\n",
              "      (lengthscale_prior): GammaPrior()\n",
              "      (raw_lengthscale_constraint): Positive()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 179,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "st_model = SingleTaskGP(\n",
        "    train_X,\n",
        "    train_Y,\n",
        "    covar_module = MaternKernel(lengthscale_prior = GammaPrior(3,6))\n",
        ")\n",
        "st_mll = ExactMarginalLogLikelihood(st_model.likelihood, st_model)\n",
        "fit_gpytorch_model(st_mll)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.2239, 0.2215, 0.2233, 0.2244, 0.2242, 0.2232, 0.2233, 0.2231, 0.2243,\n",
            "         0.2244, 0.2222, 0.2231, 0.2247, 0.2244, 0.2236, 0.2227, 0.2239, 0.2237,\n",
            "         0.2233, 0.2247]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "pca_model = SingleTaskGP(\n",
        "    train_X,\n",
        "    train_Y,\n",
        "    outcome_transform=ChainedOutcomeTransform(\n",
        "        **{\n",
        "            \"standardize\": Standardize(config[\"outcome_dim\"], min_stdv=100),\n",
        "            \"pca\": PCAOutcomeTransform(num_axes=1),\n",
        "        }\n",
        "    ),\n",
        "    likelihood=GaussianLikelihood(noise_prior=GammaPrior(0.9, 10)),\n",
        ")\n",
        "pca_mll = ExactMarginalLogLikelihood(pca_model.likelihood, pca_model)\n",
        "\n",
        "fit_gpytorch_mll(pca_mll)\n",
        "\n",
        "print(pca_model.outcome_transform['pca'].axes_learned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [],
      "source": [
        "def helper(num_test_points, models_dict, outcome_idxs):\n",
        "\n",
        "    test_X = torch.linspace(0, 1, num_test_points).unsqueeze(1).to(**tkwargs)\n",
        "    test_Y = problem.eval_metrics_true(test_X).detach()\n",
        "\n",
        "    for outcome_idx in outcome_idxs:\n",
        "\n",
        "        for model_name, model in models_dict.items():\n",
        "\n",
        "            test_Y_posterior_mean = model.posterior(test_X).mean[:, outcome_idx]\n",
        "           \n",
        "            print(model_name, 'outcome', outcome_idx, 'RMSE', torch.sqrt(torch.mean(torch.square(test_Y_posterior_mean - test_Y[:,outcome_idx]))).item())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fit_util_models(train_Y, comps, util_vals, input_transform, covar_module):\n",
        "    util_model = fit_pref_model(\n",
        "        train_Y, \n",
        "        comps, \n",
        "        input_transform = input_transform, \n",
        "        covar_module = covar_module\n",
        "    )\n",
        "    util_model_oracle = SingleTaskGP(\n",
        "        train_Y, \n",
        "        util_vals.unsqueeze(1), \n",
        "        input_transform = input_transform, \n",
        "        covar_module = covar_module\n",
        "    )\n",
        "    mll = ExactMarginalLogLikelihood(util_model_oracle.likelihood, util_model_oracle)\n",
        "    fit_gpytorch_mll(mll)\n",
        "\n",
        "    return util_model, util_model_oracle\n",
        "\n",
        "def fit_models_helper(\n",
        "    train_Y, comps, util_vals, method, axes_dict = None, \n",
        "    modify_kernel = False, a=0.2, b=5\n",
        "):\n",
        "\n",
        "    input_transform = None\n",
        "    models_dict = {}\n",
        "    if method in (\"pca\", \"pcr\"):\n",
        "        for axes_label, axes in axes_dict.items():\n",
        "            latent_dim = axes.shape[0]\n",
        "            input_transform = ChainedInputTransform(\n",
        "                        **{\n",
        "                            \"center\": InputCenter(config[\"outcome_dim\"]),\n",
        "                            \"pca\": PCAInputTransform(axes.to(torch.double)),\n",
        "                        }\n",
        "                    )\n",
        "            covar_module = make_modified_kernel(\n",
        "                ard_num_dims=latent_dim, a=a, b=b) if modify_kernel else None\n",
        "\n",
        "            util_model, util_model_oracle = fit_util_models(\n",
        "                train_Y, comps, util_vals, input_transform, covar_module)\n",
        "            models_dict[method+'_'+axes_label+'_comps'] = util_model\n",
        "            models_dict[method+'_'+axes_label+'_oracle'] = util_model_oracle\n",
        "    \n",
        "    elif method == \"st\":\n",
        "        covar_module = make_modified_kernel(ard_num_dims=train_Y.shape[-1]) if modify_kernel else None\n",
        "        input_transform = None\n",
        "        util_model, util_model_oracle = fit_util_models(\n",
        "                train_Y, comps, util_vals, input_transform, covar_module)\n",
        "        models_dict[method+'_comps'] = util_model\n",
        "        models_dict[method+'_oracle'] = util_model_oracle\n",
        "    \n",
        "    return models_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca_axes_dict = {\n",
        "    \"learned\": pca_model.outcome_transform['pca'].axes_learned,\n",
        "    \"true\": ground_truth_principal_axes # TODO: normalize\n",
        "}\n",
        "# TODO: later, run regression and add PCR_axes_dict for the rank-2 test case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca_models_dict = fit_models_helper(\n",
        "    train_Y, comps, util_vals, \n",
        "    method=\"pca\", \n",
        "    axes_dict = pca_axes_dict, \n",
        "    modify_kernel = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['pca_learned_comps', 'pca_learned_oracle', 'pca_true_comps', 'pca_true_oracle'])"
            ]
          },
          "execution_count": 185,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pca_models_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [],
      "source": [
        "st_models_dict = fit_models_helper(\n",
        "    train_Y, comps, util_vals, \n",
        "    method=\"st\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['st_comps', 'st_oracle'])"
            ]
          },
          "execution_count": 187,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "st_models_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_util_model_fit_wrapper(models_dict, seed = 0, n_test = 1000):\n",
        "    torch.manual_seed(seed)\n",
        "    acc_dict = {}\n",
        "    for model_key, model in models_dict.items():\n",
        "        print(f'checking fit of {model_key}')\n",
        "        acc = check_util_model_fit(\n",
        "            pref_model = model,\n",
        "            problem = problem,\n",
        "            util_func = util_func,\n",
        "            n_test = n_test,\n",
        "            batch_eval = True,\n",
        "            return_util_vals = False\n",
        "        )\n",
        "        acc_dict[model_key] = acc\n",
        "    \n",
        "    return acc_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checking fit of pca_learned_comps\n",
            "checking fit of pca_learned_oracle\n",
            "checking fit of pca_true_comps\n",
            "checking fit of pca_true_oracle\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'pca_learned_comps': 0.9660000205039978,\n",
              " 'pca_learned_oracle': 0.9380000233650208,\n",
              " 'pca_true_comps': 0.9319999814033508,\n",
              " 'pca_true_oracle': 0.949999988079071}"
            ]
          },
          "execution_count": 189,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "check_util_model_fit_wrapper(pca_models_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checking fit of st_comps\n",
            "checking fit of st_oracle\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'st_comps': 0.8899999856948853, 'st_oracle': 0.9879999756813049}"
            ]
          },
          "execution_count": 190,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "check_util_model_fit_wrapper(st_models_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Next TODO:\n",
        "\n",
        "# look at nonlinear utility\n",
        "# math derivation\n",
        "# PCR"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test case 2: outcome dimensionality = 20, rank = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"input_dim\": 1,\n",
        "    \"outcome_dim\": 20,\n",
        "    \"latent_dim\": 2,\n",
        "    \"PC_noise_level\": 0,\n",
        "    \"noise_std\": 1,\n",
        "    \"num_initial_samples\": 20,\n",
        "    \"num_sample_points\": 30,\n",
        "    \"jitter\": 0.00001,  # noqa\n",
        "    \"ground_truth_principal_axes\": torch.Tensor([[1]*20, [1]*10+[-1]*10]),\n",
        "    \"PC_lengthscales\": [0.1, 0.1],\n",
        "    \"PC_scaling_factors\": [2, 1],\n",
        "    \"variance_explained_threshold\": 0.99,\n",
        "}\n",
        "\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "ground_truth_principal_axes = config['ground_truth_principal_axes']\n",
        "\n",
        "initial_X = torch.randn((config[\"num_initial_samples\"], config[\"input_dim\"]), **tkwargs)\n",
        "\n",
        "obj_indices = list(range(config[\"outcome_dim\"]))\n",
        "cons_indices = []\n",
        "\n",
        "problem = PCATestProblem(\n",
        "    opt_config=(obj_indices, cons_indices),\n",
        "    initial_X=initial_X,\n",
        "    bounds=torch.Tensor([[0, 1]] * config[\"input_dim\"]),\n",
        "    ground_truth_principal_axes=ground_truth_principal_axes,\n",
        "    noise_std=config[\"noise_std\"],\n",
        "    PC_lengthscales=Tensor(config[\"PC_lengthscales\"]),\n",
        "    PC_scaling_factors=Tensor(config[\"PC_scaling_factors\"]),\n",
        "    dtype=torch.double,\n",
        ")\n",
        "\n",
        "use_modified_kernel = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "beta = torch.tensor([1]*10+[-1]*10)\n",
        "util_func = LinearUtil(beta=beta)\n",
        "\n",
        "train_X, train_Y, util_vals, comps = gen_initial_real_data(n=100, problem=problem, util_func=util_func)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([100, 20]), torch.Size([100]), torch.Size([50, 2]))"
            ]
          },
          "execution_count": 226,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_Y.shape, util_vals.shape, comps.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ExactMarginalLogLikelihood(\n",
              "  (likelihood): GaussianLikelihood(\n",
              "    (noise_covar): HomoskedasticNoise(\n",
              "      (noise_prior): GammaPrior()\n",
              "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
              "    )\n",
              "  )\n",
              "  (model): SingleTaskGP(\n",
              "    (likelihood): GaussianLikelihood(\n",
              "      (noise_covar): HomoskedasticNoise(\n",
              "        (noise_prior): GammaPrior()\n",
              "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
              "      )\n",
              "    )\n",
              "    (mean_module): ConstantMean()\n",
              "    (covar_module): MaternKernel(\n",
              "      (lengthscale_prior): GammaPrior()\n",
              "      (raw_lengthscale_constraint): Positive()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 227,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "st_model_low = SingleTaskGP(\n",
        "    train_X,\n",
        "    train_Y,\n",
        "    covar_module = MaternKernel(lengthscale_prior = GammaPrior(3,6))\n",
        ")\n",
        "st_mll_low = ExactMarginalLogLikelihood(st_model_low.likelihood, st_model_low)\n",
        "fit_gpytorch_mll(st_mll_low)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.2780, 0.2552, 0.2686, 0.2774, 0.2745, 0.2677, 0.2684, 0.2645, 0.2754,\n",
            "         0.2773, 0.1489, 0.1568, 0.1746, 0.1681, 0.1608, 0.1522, 0.1656, 0.1671,\n",
            "         0.1605, 0.1762]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "options = {\"maxiter\": 1000}\n",
        "\n",
        "pca_model_low = SingleTaskGP(\n",
        "    train_X,\n",
        "    train_Y,\n",
        "    outcome_transform=ChainedOutcomeTransform(\n",
        "        **{\n",
        "            \"standardize\": Standardize(config[\"outcome_dim\"], min_stdv=100),\n",
        "            \"pca\": PCAOutcomeTransform(num_axes=1),\n",
        "        }\n",
        "    ),\n",
        "    likelihood=GaussianLikelihood(noise_prior=GammaPrior(0.9, 10)),\n",
        ")\n",
        "pca_mll_low = ExactMarginalLogLikelihood(pca_model_low.likelihood, pca_model_low)\n",
        "\n",
        "fit_gpytorch_mll(pca_mll_low)\n",
        "\n",
        "print(pca_model_low.outcome_transform['pca'].axes_learned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca_axes_dict = {\n",
        "    \"learned\": pca_model_low.outcome_transform['pca'].axes_learned,\n",
        "    \"true\": ground_truth_principal_axes # TODO: normalize\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca_models_dict = fit_models_helper(\n",
        "    train_Y, comps, util_vals, \n",
        "    method=\"pca\", \n",
        "    axes_dict = pca_axes_dict, \n",
        "    modify_kernel = True,\n",
        "    a=0.001,\n",
        "    b=1000\n",
        ")\n",
        "st_models_dict = fit_models_helper(\n",
        "    train_Y, comps, util_vals, \n",
        "    method=\"st\", \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checking fit of pca_learned_comps\n"
          ]
        },
        {
          "ename": "NotPSDError",
          "evalue": "Matrix not positive definite after repeatedly adding jitter up to 1.0e-01.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotPSDError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_842565/360902351.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheck_util_model_fit_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca_models_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_842565/849976444.py\u001b[0m in \u001b[0;36mcheck_util_model_fit_wrapper\u001b[0;34m(models_dict, seed, n_test)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'checking fit of {model_key}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         acc = check_util_model_fit(\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mpref_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mproblem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/low_rank_BOPE/low_rank_BOPE/src/diagnostics.py\u001b[0m in \u001b[0;36mcheck_util_model_fit\u001b[0;34m(pref_model, problem, util_func, n_test, batch_eval, return_util_vals)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;31m# run pref_model on test data, get predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0mposterior_util_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpref_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0mposterior_util_mean_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposterior_util_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_test\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/bope_pca/lib/python3.9/site-packages/botorch/models/pairwise_gp.py\u001b[0m in \u001b[0;36mposterior\u001b[0;34m(self, X, output_indices, observation_noise, posterior_transform, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m             )\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m         \u001b[0mpost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0mposterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPyTorchPosterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mposterior_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/bope_pca/lib/python3.9/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/bope_pca/lib/python3.9/site-packages/botorch/models/pairwise_gp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, datapoints)\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# perform a cholesky decomposition to check and amend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             covariance_matrix=RootLinearOperator(\n\u001b[0;32m--> 857\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaled_psd_safe_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_covar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jitter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m             ),\n\u001b[1;32m    859\u001b[0m         )\n",
            "\u001b[0;32m~/anaconda3/envs/bope_pca/lib/python3.9/site-packages/botorch/models/pairwise_gp.py\u001b[0m in \u001b[0;36m_scaled_psd_safe_cholesky\u001b[0;34m(self, M, jitter)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovar_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mchol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsd_safe_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjitter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0mchol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mchol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/bope_pca/lib/python3.9/site-packages/linear_operator/utils/cholesky.py\u001b[0m in \u001b[0;36mpsd_safe_cholesky\u001b[0;34m(A, upper, out, jitter, max_tries)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mNumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mattempts\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mwith\u001b[0m \u001b[0msuccessively\u001b[0m \u001b[0mincreasing\u001b[0m \u001b[0mjitter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mto\u001b[0m \u001b[0mmake\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mraising\u001b[0m \u001b[0man\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \"\"\"\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_psd_safe_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjitter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_tries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/bope_pca/lib/python3.9/site-packages/linear_operator/utils/cholesky.py\u001b[0m in \u001b[0;36m_psd_safe_cholesky\u001b[0;34m(A, out, jitter, max_tries)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotPSDError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Matrix not positive definite after repeatedly adding jitter up to {jitter_new:.1e}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotPSDError\u001b[0m: Matrix not positive definite after repeatedly adding jitter up to 1.0e-01."
          ]
        }
      ],
      "source": [
        "check_util_model_fit_wrapper(pca_models_dict, n_test = 50)\n",
        "\n",
        "# the nonPSD error probably is a byproduct of the fully orthogonal utility function\n",
        "# we'd get all-zero utilities for the PCA model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checking fit of st_comps\n",
            "checking fit of st_oracle\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'st_comps': 0.8159999847412109, 'st_oracle': 0.9300000071525574}"
            ]
          },
          "execution_count": 203,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "check_util_model_fit_wrapper(st_models_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "bento_stylesheets": {
      "bento/extensions/flow/main.css": true,
      "bento/extensions/kernel_selector/main.css": true,
      "bento/extensions/kernel_ui/main.css": true,
      "bento/extensions/new_kernel/main.css": true,
      "bento/extensions/system_usage/main.css": true,
      "bento/extensions/theme/main.css": true
    },
    "captumWidgetMessage": {},
    "dataExplorerConfig": {},
    "disseminate_notebook_id": {
      "notebook_id": "310500951141609"
    },
    "disseminate_notebook_info": {
      "bento_version": "20220213-210538",
      "data_retention_policy": "default",
      "description": "",
      "hide_code": false,
      "hipster_group": "",
      "kernel_build_info": {
        "deps": [
          "//ae:notebook",
          "//ax/ax/utils/tutorials:tutorial_utils"
        ],
        "external_deps": [],
        "kernel_version": "1206"
      },
      "no_uii": true,
      "notebook_number": "1613503",
      "others_can_edit": false,
      "reviewers": "",
      "revision_id": "668025524236855",
      "tags": "",
      "tasks": "",
      "title": "QE_Lib_ae_ig_feed_recs_sourcing_quickbo_relax_media_age_analysis_b2"
    },
    "interpreter": {
      "hash": "f178f7686bb85c5c6e141a85fd4c17c3082d63b89f6cfaecdf98c22c0047a219"
    },
    "kernelspec": {
      "display_name": "Python 3.9.15 ('bope_pca')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "last_base_url": "https://devvm10848.prn0.facebook.com:8090/",
    "last_kernel_id": "33f76217-c3bb-4b3c-be64-89415980d364",
    "last_msg_id": "33163635-cf61d68d283ac2575827f13f_324",
    "last_server_session_id": "e5067c57-e1d5-4267-b323-2335fc1b1e29",
    "outputWidgetContext": {}
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
