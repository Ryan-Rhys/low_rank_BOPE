{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "code_folding": [],
        "customInput": null,
        "hidden_ranges": [],
        "originalKey": "c2748393-d4ea-4830-94f2-145dc2fb0c14",
        "showInput": false
      },
      "source": [
        "# Overview\n",
        "\n",
        "In this notebook, we generate synthetic low-rank outcome data and test different ways of learning the utility model:\n",
        "- fit indepdendent GPs to each outcome\n",
        "- learn a PCA decomposition, fit independent GPs to the top principal components that explain most variance\n",
        "- learn a PCA decomposition, select top PCs that explain the utility, fit independent GPs to them\n",
        "\n",
        "We look at a few test cases here:\n",
        "- outcome dimensionality = 10, rank = 1; linear utility function is different from (but not orthogonal to) the outcome axis\n",
        "- outcome dimensionality = 20, rank = 1; linear utility function points in the same direction as outcome axis\n",
        "- outcome dimensionality = 20, rank = 2; utility depends on both axes\n",
        "\n",
        "For each of these test cases, we try the following different embeddings:\n",
        "- the ground truth low-rank subspace\n",
        "- the low-rank subspace learned by doing PCA\n",
        "- the low-rank subspace given by the utility function\n",
        "- (later) the low=rank subspace learned by doing PCR\n",
        "\n",
        "Test case 0 helps us test the hypothesis: learning utility-informed embedding is better than utility-agnostic embedding, especially when utility coefficient is not well-aligned with major axes of variation in the outcomes\n",
        "\n",
        "Test case 1 helps us answer the question: Does PCA do better than Indep? Is it because it's easier to learn the PCA matrix than the independent GP hyperparameters?\n",
        "\n",
        "Test case 2 helps us compare PCA and PCR. We expect PCR to do better than PCA in this case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "code_folding": [],
        "collapsed": false,
        "customOutput": null,
        "executionStartTime": 1673017165515,
        "executionStopTime": 1673017169427,
        "hidden_ranges": [],
        "originalKey": "ed006d17-14ef-41a2-9b4f-6163953a6ec9",
        "requestMsgId": "c593f2fe-2fb2-4595-9412-d4a68b8971a6",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/yz685/anaconda3/envs/bope_pca/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os, sys\n",
        "# file_dir = os.path.dirname(__file__)\n",
        "# sys.path.append(file_dir)\n",
        "sys.path.append('/home/yz685/low_rank_BOPE')\n",
        "sys.path.append('/home/yz685/low_rank_BOPE/low_rank_BOPE')\n",
        "import warnings\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.linalg\n",
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "from test_problems.synthetic_problem import generate_principal_axes, PCATestProblem\n",
        "from src.transforms import (\n",
        "    generate_random_projection,\n",
        "    InputCenter,\n",
        "    LinearProjectionInputTransform,\n",
        "    LinearProjectionOutcomeTransform,\n",
        "    PCAInputTransform,\n",
        "    PCAOutcomeTransform,\n",
        "    SubsetOutcomeTransform,\n",
        ")\n",
        "from src.pref_learning_helpers import gen_initial_real_data, fit_pref_model\n",
        "from src.diagnostics import check_util_model_fit\n",
        "from src.models import make_modified_kernel\n",
        "\n",
        "# import botorch, gpytorch functions\n",
        "from botorch import fit_gpytorch_model, fit_gpytorch_mll\n",
        "from botorch.optim.fit import fit_gpytorch_scipy\n",
        "from botorch.optim.utils import _filter_kwargs\n",
        "from botorch.utils.sampling import draw_sobol_samples\n",
        "from botorch.models import SingleTaskGP\n",
        "from botorch.models.transforms.outcome import ChainedOutcomeTransform, Standardize\n",
        "from botorch.models.transforms.input import (\n",
        "    ChainedInputTransform,\n",
        "    FilterFeatures,\n",
        "    Normalize,\n",
        ")\n",
        "\n",
        "from gpytorch.kernels import MaternKernel\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from gpytorch.likelihoods import GaussianLikelihood\n",
        "from gpytorch.priors import GammaPrior\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "tkwargs = {\n",
        "    \"dtype\": torch.double,\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
        "}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Helper functions and classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_problem(**kwargs):\n",
        "    \"\"\"\n",
        "    Create test problem with specified low-rank structure.\n",
        "    \"\"\"\n",
        "\n",
        "    # default config\n",
        "    config = {\n",
        "        \"input_dim\": 1,\n",
        "        # \"outcome_dim\": 20,\n",
        "        \"latent_dim\": 1,\n",
        "        \"PC_noise_level\": 0,\n",
        "        \"noise_std\": 0.1,\n",
        "        \"num_initial_samples\": 20,\n",
        "        \"num_sample_points\": 30,\n",
        "        # \"ground_truth_principal_axes\": torch.Tensor([1]*20),\n",
        "        \"PC_lengthscales\": [0.1],\n",
        "        \"PC_scaling_factors\": [2],\n",
        "        \"variance_explained_threshold\": 0.99,\n",
        "    }\n",
        "\n",
        "    # overwrite config settings with kwargs\n",
        "    for key, val in kwargs.items():\n",
        "        config[key] = val\n",
        "\n",
        "    torch.manual_seed(1234)\n",
        "    initial_X = torch.randn((config[\"num_initial_samples\"], config[\"input_dim\"]), **tkwargs)\n",
        "\n",
        "    obj_indices = list(range(config[\"outcome_dim\"]))\n",
        "    cons_indices = []\n",
        "\n",
        "    if len(config['ground_truth_principal_axes'].shape) == 1:\n",
        "        config['ground_truth_principal_axes'] = config['ground_truth_principal_axes'].unsqueeze(0)\n",
        "\n",
        "    problem = PCATestProblem(\n",
        "        opt_config=(obj_indices, cons_indices),\n",
        "        initial_X=initial_X,\n",
        "        bounds=torch.Tensor([[0, 1]] * config[\"input_dim\"]),\n",
        "        ground_truth_principal_axes=config['ground_truth_principal_axes'],\n",
        "        noise_std=config[\"noise_std\"],\n",
        "        PC_lengthscales=Tensor(config[\"PC_lengthscales\"]),\n",
        "        PC_scaling_factors=Tensor(config[\"PC_scaling_factors\"]),\n",
        "        dtype=torch.double,\n",
        "    )\n",
        "\n",
        "    return problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LinearUtil(torch.nn.Module):\n",
        "    \"\"\" \n",
        "    Create linear utility function modulew with specified coefficient beta.\n",
        "    f(y) = beta_1 * y_1 + ... + beta_k * y_k\n",
        "    \"\"\"\n",
        "    def __init__(self, beta: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            beta: size `output_dim` tensor\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.register_buffer(\"beta\", beta)\n",
        "\n",
        "    def calc_raw_util_per_dim(self, Y):\n",
        "        return Y * self.beta.to(Y)\n",
        "\n",
        "    def forward(self, Y, X=None):\n",
        "        return Y @ self.beta.to(Y)\n",
        "\n",
        "class SumOfSquaresUtil(torch.nn.Module):\n",
        "    \"\"\" \n",
        "    Create sum of squares utility function modulew with specified coefficient beta.\n",
        "    f(y) = beta_1 * y_1^2 + ... + beta_k * y_k^2\n",
        "    \"\"\"\n",
        "    def __init__(self, beta: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            beta: size `output_dim` tensor\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.register_buffer(\"beta\", beta)\n",
        "\n",
        "    def calc_raw_util_per_dim(self, Y):\n",
        "        return torch.square(Y) * self.beta.to(Y)\n",
        "\n",
        "    def forward(self, Y, X=None):\n",
        "        return torch.square(Y) @ self.beta.to(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def RMSE_helper(num_test_points, models_dict, outcome_idxs):\n",
        "    \"\"\" \n",
        "    (Not used in this NB) Compute root mean squared error of GP posterior predictions.\n",
        "    \"\"\"\n",
        "\n",
        "    test_X = torch.linspace(0, 1, num_test_points).unsqueeze(1).to(**tkwargs)\n",
        "    test_Y = problem.eval_metrics_true(test_X).detach()\n",
        "\n",
        "    for outcome_idx in outcome_idxs:\n",
        "\n",
        "        for model_name, model in models_dict.items():\n",
        "\n",
        "            test_Y_posterior_mean = model.posterior(test_X).mean[:, outcome_idx]\n",
        "           \n",
        "            print(\n",
        "                model_name, \n",
        "                'outcome', outcome_idx, \n",
        "                'RMSE', torch.sqrt(torch.mean(\n",
        "                    torch.square(test_Y_posterior_mean - test_Y[:,outcome_idx])\n",
        "                )).item()\n",
        "            )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fit_util_models(train_Y, comps, util_vals, input_transform, covar_module):\n",
        "    \"\"\" \n",
        "    Fit utility model given (1) comparisons (2) ground truth utility values.\n",
        "    Return the two fitted GPs.\n",
        "    (In practice, fitting model (2) is usually not feasible.)\n",
        "    \"\"\"\n",
        "    util_model_rel = fit_pref_model(\n",
        "        train_Y, \n",
        "        comps, \n",
        "        input_transform = input_transform, \n",
        "        covar_module = covar_module\n",
        "    )\n",
        "    util_model_abs = SingleTaskGP(\n",
        "        train_Y, \n",
        "        util_vals.unsqueeze(1), \n",
        "        input_transform = input_transform, \n",
        "        covar_module = covar_module\n",
        "    )\n",
        "    mll = ExactMarginalLogLikelihood(util_model_abs.likelihood, util_model_abs)\n",
        "    fit_gpytorch_mll(mll)\n",
        "\n",
        "    return util_model_rel, util_model_abs\n",
        "\n",
        "def fit_models_helper(\n",
        "    train_Y, comps, util_vals, method, axes_dict = None, \n",
        "    modify_kernel = False, a=0.2, b=5\n",
        "):\n",
        "    \"\"\" \n",
        "    Fit utility models for different methods (st, pca, pcr) and potentially a \n",
        "    set of different axes in `axes_dict`. If specified, also modify the hyperpriors \n",
        "    of the input covar_module based on the supplied parameter value `a` and `b`.\n",
        "    Return the fitted models in a dictionary. The suffix '_rel' means the model\n",
        "    is fit on pairwise comparisons; the suffix '_abs' means the model is fit on \n",
        "    ground truth utility values.\n",
        "    \"\"\"\n",
        "    input_transform = None\n",
        "    models_dict = {}\n",
        "    if method in (\"pca\", \"pcr\"):\n",
        "        for axes_label, axes in axes_dict.items():\n",
        "            latent_dim = axes.shape[0]\n",
        "            input_transform = ChainedInputTransform(\n",
        "                        **{\n",
        "                            \"center\": InputCenter(train_Y.shape[-1]),\n",
        "                            \"pca\": PCAInputTransform(axes.to(torch.double)),\n",
        "                        }\n",
        "                    )\n",
        "            covar_module = make_modified_kernel(\n",
        "                ard_num_dims=latent_dim, a=a, b=b) if modify_kernel else None\n",
        "\n",
        "            util_model_rel, util_model_abs = fit_util_models(\n",
        "                train_Y, comps, util_vals, input_transform, covar_module)\n",
        "            models_dict[method+'_'+axes_label+'_rel'] = util_model_rel\n",
        "            models_dict[method+'_'+axes_label+'_abs'] = util_model_abs\n",
        "    \n",
        "    elif method == \"st\":\n",
        "        covar_module = make_modified_kernel(ard_num_dims=train_Y.shape[-1]) if modify_kernel else None\n",
        "        input_transform = None\n",
        "        util_model_rel, util_model_abs = fit_util_models(\n",
        "                train_Y, comps, util_vals, input_transform, covar_module)\n",
        "        models_dict[method+'_rel'] = util_model_rel\n",
        "        models_dict[method+'_abs'] = util_model_abs\n",
        "    \n",
        "    return models_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_util_model_fit_wrapper(problem, util_func, models_dict, seed = 0, n_test = 1000):\n",
        "    \"\"\" \n",
        "    Check the accuracy of preference prediction of the models in `models_dict` \n",
        "    on a separate test set. Return the accuracy in a dictionary. \n",
        "    \"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    acc_dict = {}\n",
        "    for model_key, model in models_dict.items():\n",
        "        print(f'checking fit of {model_key}')\n",
        "        acc = check_util_model_fit(\n",
        "            pref_model = model,\n",
        "            problem = problem,\n",
        "            util_func = util_func,\n",
        "            n_test = n_test,\n",
        "            batch_eval = True,\n",
        "            return_util_vals = False\n",
        "        )\n",
        "        acc_dict[model_key] = acc\n",
        "    \n",
        "    return acc_dict"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test case 0: outcome dimensionality = 10, rank = 1, axis = (1,0,...,0), linear utility coeff = (1,1,0,...,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_X, train_Y shape:  torch.Size([100, 1]) torch.Size([100, 10])\n"
          ]
        }
      ],
      "source": [
        "ground_truth_principal_axes = torch.Tensor([1]+[0]*9)\n",
        "\n",
        "problem = make_problem(\n",
        "    outcome_dim = 10,\n",
        "    ground_truth_principal_axes = ground_truth_principal_axes\n",
        ")\n",
        "\n",
        "torch.manual_seed(123)\n",
        "beta = torch.tensor([1,1]+[0]*8, **tkwargs)\n",
        "util_func = LinearUtil(beta=beta)\n",
        "\n",
        "train_X, train_Y, util_vals, comps = gen_initial_real_data(n=100, problem=problem, util_func=util_func)\n",
        "print('train_X, train_Y shape: ', train_X.shape, train_Y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 9.9980e-01, -2.5584e-03, -6.8475e-03, -2.4620e-03, -6.7253e-03,\n",
            "         -7.7932e-04, -2.3186e-03, -4.3601e-03,  1.6223e-02, -1.4621e-03]],\n",
            "       dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "st_model = SingleTaskGP(\n",
        "    train_X,\n",
        "    train_Y,\n",
        "    covar_module = MaternKernel(lengthscale_prior = GammaPrior(3,6))\n",
        ")\n",
        "st_mll = ExactMarginalLogLikelihood(st_model.likelihood, st_model)\n",
        "fit_gpytorch_model(st_mll)\n",
        "\n",
        "pca_model = SingleTaskGP(\n",
        "    train_X,\n",
        "    train_Y,\n",
        "    outcome_transform=ChainedOutcomeTransform(\n",
        "        **{\n",
        "            \"standardize\": Standardize(10, min_stdv=100),\n",
        "            \"pca\": PCAOutcomeTransform(num_axes=1),\n",
        "        }\n",
        "    ),\n",
        "    likelihood=GaussianLikelihood(noise_prior=GammaPrior(0.9, 10)),\n",
        ")\n",
        "pca_mll = ExactMarginalLogLikelihood(pca_model.likelihood, pca_model)\n",
        "\n",
        "fit_gpytorch_mll(pca_mll)\n",
        "\n",
        "print(pca_model.outcome_transform['pca'].axes_learned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'learned': tensor([[ 9.9980e-01, -2.5584e-03, -6.8475e-03, -2.4620e-03, -6.7253e-03,\n",
            "         -7.7932e-04, -2.3186e-03, -4.3601e-03,  1.6223e-02, -1.4621e-03]],\n",
            "       dtype=torch.float64), 'true': tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'oracle': tensor([[1., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)}\n"
          ]
        }
      ],
      "source": [
        "# create dict of axes\n",
        "\n",
        "pca_axes_dict = {\n",
        "    \"learned\": pca_model.outcome_transform['pca'].axes_learned,\n",
        "    \"true\": ground_truth_principal_axes.unsqueeze(0),\n",
        "    \"oracle\": beta.unsqueeze(0) # utility coefficient\n",
        "}\n",
        "\n",
        "print(pca_axes_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['pca_learned_rel', 'pca_learned_abs', 'pca_true_rel', 'pca_true_abs', 'pca_oracle_rel', 'pca_oracle_abs'])\n",
            "checking fit of pca_learned_rel\n",
            "checking fit of pca_learned_abs\n",
            "checking fit of pca_true_rel\n",
            "checking fit of pca_true_abs\n",
            "checking fit of pca_oracle_rel\n",
            "checking fit of pca_oracle_abs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'pca_learned_rel': 0.9800000190734863,\n",
              " 'pca_learned_abs': 0.9860000014305115,\n",
              " 'pca_true_rel': 0.972000002861023,\n",
              " 'pca_true_abs': 0.9760000109672546,\n",
              " 'pca_oracle_rel': 1.0,\n",
              " 'pca_oracle_abs': 1.0}"
            ]
          },
          "execution_count": 254,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pca_models_dict = fit_models_helper(\n",
        "    train_Y, comps, util_vals, \n",
        "    method=\"pca\", \n",
        "    axes_dict = pca_axes_dict, \n",
        "    modify_kernel = True\n",
        ")\n",
        "\n",
        "print(pca_models_dict.keys())\n",
        "\n",
        "check_util_model_fit_wrapper(problem, util_func, pca_models_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['st_rel', 'st_abs'])\n",
            "checking fit of st_rel\n",
            "checking fit of st_abs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'st_rel': 0.9380000233650208, 'st_abs': 0.9980000257492065}"
            ]
          },
          "execution_count": 255,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "st_models_dict = fit_models_helper(\n",
        "    train_Y, comps, util_vals, \n",
        "    method=\"st\"\n",
        ")\n",
        "\n",
        "print(st_models_dict.keys())\n",
        "\n",
        "check_util_model_fit_wrapper(problem, util_func, st_models_dict)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test case 1: outcome dimensionality = 20, rank = 1, axis = linear utility coeff = (1,1,...,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "code_folding": [],
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStopTime": 1654062966426,
        "hidden_ranges": [],
        "originalKey": "61a998be-17b2-430a-bb83-f540b1c4ae41",
        "requestMsgId": "61a998be-17b2-430a-bb83-f540b1c4ae41",
        "showInput": true
      },
      "outputs": [],
      "source": [
        "ground_truth_principal_axes = torch.Tensor([1]*20)\n",
        "\n",
        "problem = make_problem(\n",
        "    outcome_dim = 20,\n",
        "    ground_truth_principal_axes = ground_truth_principal_axes,\n",
        ")\n",
        "\n",
        "torch.manual_seed(123)\n",
        "beta = torch.tensor([1]*20, **tkwargs)\n",
        "util_func = LinearUtil(beta=beta)\n",
        "\n",
        "train_X, train_Y, util_vals, comps = gen_initial_real_data(n=150, problem=problem, util_func=util_func)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ExactMarginalLogLikelihood(\n",
              "  (likelihood): GaussianLikelihood(\n",
              "    (noise_covar): HomoskedasticNoise(\n",
              "      (noise_prior): GammaPrior()\n",
              "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
              "    )\n",
              "  )\n",
              "  (model): SingleTaskGP(\n",
              "    (likelihood): GaussianLikelihood(\n",
              "      (noise_covar): HomoskedasticNoise(\n",
              "        (noise_prior): GammaPrior()\n",
              "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
              "      )\n",
              "    )\n",
              "    (mean_module): ConstantMean()\n",
              "    (covar_module): MaternKernel(\n",
              "      (lengthscale_prior): GammaPrior()\n",
              "      (raw_lengthscale_constraint): Positive()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "st_model = SingleTaskGP(\n",
        "    train_X,\n",
        "    train_Y,\n",
        "    covar_module = MaternKernel(lengthscale_prior = GammaPrior(3,6))\n",
        ")\n",
        "st_mll = ExactMarginalLogLikelihood(st_model.likelihood, st_model)\n",
        "fit_gpytorch_model(st_mll)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.2245, 0.2223, 0.2241, 0.2232, 0.2243, 0.2223, 0.2223, 0.2232, 0.2235,\n",
            "         0.2245, 0.2240, 0.2218, 0.2223, 0.2246, 0.2233, 0.2239, 0.2233, 0.2234,\n",
            "         0.2250, 0.2264]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "pca_model = SingleTaskGP(\n",
        "    train_X,\n",
        "    train_Y,\n",
        "    outcome_transform=ChainedOutcomeTransform(\n",
        "        **{\n",
        "            \"standardize\": Standardize(20, min_stdv=100),\n",
        "            \"pca\": PCAOutcomeTransform(num_axes=1),\n",
        "        }\n",
        "    ),\n",
        "    likelihood=GaussianLikelihood(noise_prior=GammaPrior(0.9, 10)),\n",
        ")\n",
        "pca_mll = ExactMarginalLogLikelihood(pca_model.likelihood, pca_model)\n",
        "\n",
        "fit_gpytorch_mll(pca_mll)\n",
        "\n",
        "print(pca_model.outcome_transform['pca'].axes_learned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca_axes_dict = {\n",
        "    \"learned\": pca_model.outcome_transform['pca'].axes_learned,\n",
        "    \"true\": ground_truth_principal_axes.unsqueeze(0),\n",
        "    \"oracle\": beta.unsqueeze(0) # utility coefficient\n",
        "}\n",
        "# TODO: later, run regression and add PCR_axes_dict for the rank-2 test case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['pca_learned_rel', 'pca_learned_abs', 'pca_true_rel', 'pca_true_abs', 'pca_oracle_rel', 'pca_oracle_abs'])\n",
            "checking fit of pca_learned_rel\n",
            "checking fit of pca_learned_abs\n",
            "checking fit of pca_true_rel\n",
            "checking fit of pca_true_abs\n",
            "checking fit of pca_oracle_rel\n",
            "checking fit of pca_oracle_abs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'pca_learned_rel': 1.0,\n",
              " 'pca_learned_abs': 0.8666666746139526,\n",
              " 'pca_true_rel': 0.8666666746139526,\n",
              " 'pca_true_abs': 1.0,\n",
              " 'pca_oracle_rel': 1.0,\n",
              " 'pca_oracle_abs': 0.8666666746139526}"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pca_models_dict = fit_models_helper(\n",
        "    train_Y, comps, util_vals, \n",
        "    method=\"pca\", \n",
        "    axes_dict = pca_axes_dict, \n",
        "    modify_kernel = True\n",
        ")\n",
        "\n",
        "print(pca_models_dict.keys())\n",
        "\n",
        "check_util_model_fit_wrapper(problem, util_func, pca_models_dict, n_test=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['st_rel', 'st_abs'])\n",
            "checking fit of st_rel\n",
            "checking fit of st_abs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'st_rel': 0.9300000071525574, 'st_abs': 0.9959999918937683}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "st_models_dict = fit_models_helper(\n",
        "    train_Y, comps, util_vals, \n",
        "    method=\"st\"\n",
        ")\n",
        "\n",
        "print(st_models_dict.keys())\n",
        "\n",
        "check_util_model_fit_wrapper(problem, util_func, st_models_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Next TODO:\n",
        "\n",
        "# look at nonlinear utility\n",
        "# math derivation\n",
        "# PCR"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test case 2: outcome dimensionality = 20, rank = 2, axis_1 = [1]x10+[0]x10, axis_2 = [0]x10+[1]x10, linear util coeff = [1]x20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "ground_truth_principal_axes = torch.Tensor([[1]*10+[0]*10, [0]*10+[1]*10])\n",
        "\n",
        "problem = make_problem(\n",
        "    outcome_dim = 20,\n",
        "    ground_truth_principal_axes = ground_truth_principal_axes,\n",
        "    noise_std = 1,\n",
        "    PC_lengthscales = [0.1, 0.1],\n",
        "    PC_scaling_factors = [2, 0.2]\n",
        ")\n",
        "\n",
        "torch.manual_seed(123)\n",
        "beta = torch.tensor([1]*20, **tkwargs)\n",
        "util_func = LinearUtil(beta=beta)\n",
        "\n",
        "train_X, train_Y, util_vals, comps = gen_initial_real_data(n=200, problem=problem, util_func=util_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ExactMarginalLogLikelihood(\n",
              "  (likelihood): GaussianLikelihood(\n",
              "    (noise_covar): HomoskedasticNoise(\n",
              "      (noise_prior): GammaPrior()\n",
              "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
              "    )\n",
              "  )\n",
              "  (model): SingleTaskGP(\n",
              "    (likelihood): GaussianLikelihood(\n",
              "      (noise_covar): HomoskedasticNoise(\n",
              "        (noise_prior): GammaPrior()\n",
              "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
              "      )\n",
              "    )\n",
              "    (mean_module): ConstantMean()\n",
              "    (covar_module): MaternKernel(\n",
              "      (lengthscale_prior): GammaPrior()\n",
              "      (raw_lengthscale_constraint): Positive()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "st_model_low = SingleTaskGP(\n",
        "    train_X,\n",
        "    train_Y,\n",
        "    covar_module = MaternKernel(lengthscale_prior = GammaPrior(3,6))\n",
        ")\n",
        "st_mll_low = ExactMarginalLogLikelihood(st_model_low.likelihood, st_model_low)\n",
        "fit_gpytorch_mll(st_mll_low)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.3200,  0.3147,  0.3040,  0.2990,  0.3065,  0.3177,  0.3301,  0.3432,\n",
            "          0.3067,  0.3132,  0.0366,  0.0190,  0.0253,  0.0167,  0.0158,  0.0032,\n",
            "         -0.0013, -0.0071,  0.0004,  0.0122]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "options = {\"maxiter\": 1000}\n",
        "\n",
        "pca_model = SingleTaskGP(\n",
        "    train_X,\n",
        "    train_Y,\n",
        "    outcome_transform=ChainedOutcomeTransform(\n",
        "        **{\n",
        "            \"standardize\": Standardize(20, min_stdv=100),\n",
        "            \"pca\": PCAOutcomeTransform(num_axes=1),\n",
        "        }\n",
        "    ),\n",
        "    likelihood=GaussianLikelihood(noise_prior=GammaPrior(0.9, 10)),\n",
        ")\n",
        "pca_mll = ExactMarginalLogLikelihood(pca_model.likelihood, pca_model)\n",
        "\n",
        "fit_gpytorch_mll(pca_mll)\n",
        "\n",
        "print(pca_model.outcome_transform['pca'].axes_learned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca_axes_dict = {\n",
        "    \"learned\": pca_model.outcome_transform['pca'].axes_learned,\n",
        "    \"true\": ground_truth_principal_axes,\n",
        "    \"oracle\": beta.unsqueeze(0) # utility coefficient\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['pca_learned_rel', 'pca_learned_abs', 'pca_true_rel', 'pca_true_abs', 'pca_oracle_rel', 'pca_oracle_abs'])\n",
            "checking fit of pca_learned_rel\n",
            "checking fit of pca_learned_abs\n",
            "checking fit of pca_true_rel\n",
            "checking fit of pca_true_abs\n",
            "checking fit of pca_oracle_rel\n",
            "checking fit of pca_oracle_abs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'pca_learned_rel': 0.9399999976158142,\n",
              " 'pca_learned_abs': 0.9599999785423279,\n",
              " 'pca_true_rel': 0.9599999785423279,\n",
              " 'pca_true_abs': 1.0,\n",
              " 'pca_oracle_rel': 1.0,\n",
              " 'pca_oracle_abs': 1.0}"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pca_models_dict = fit_models_helper(\n",
        "    train_Y, comps, util_vals, \n",
        "    method=\"pca\", \n",
        "    axes_dict = pca_axes_dict, \n",
        "    modify_kernel = True\n",
        ")\n",
        "\n",
        "print(pca_models_dict.keys())\n",
        "\n",
        "check_util_model_fit_wrapper(problem, util_func, pca_models_dict, n_test = 100)\n",
        "\n",
        "# nonPSD because you'd get the same util for data points that differ only in the outcome dimensions that don't matter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['st_rel', 'st_abs'])\n",
            "checking fit of st_rel\n",
            "checking fit of st_abs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'st_rel': 0.6000000238418579, 'st_abs': 0.765999972820282}"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "st_models_dict = fit_models_helper(\n",
        "    train_Y, comps, util_vals, \n",
        "    method=\"st\"\n",
        ")\n",
        "\n",
        "print(st_models_dict.keys())\n",
        "\n",
        "check_util_model_fit_wrapper(problem, util_func, st_models_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "bento_stylesheets": {
      "bento/extensions/flow/main.css": true,
      "bento/extensions/kernel_selector/main.css": true,
      "bento/extensions/kernel_ui/main.css": true,
      "bento/extensions/new_kernel/main.css": true,
      "bento/extensions/system_usage/main.css": true,
      "bento/extensions/theme/main.css": true
    },
    "captumWidgetMessage": {},
    "dataExplorerConfig": {},
    "disseminate_notebook_id": {
      "notebook_id": "310500951141609"
    },
    "disseminate_notebook_info": {
      "bento_version": "20220213-210538",
      "data_retention_policy": "default",
      "description": "",
      "hide_code": false,
      "hipster_group": "",
      "kernel_build_info": {
        "deps": [
          "//ae:notebook",
          "//ax/ax/utils/tutorials:tutorial_utils"
        ],
        "external_deps": [],
        "kernel_version": "1206"
      },
      "no_uii": true,
      "notebook_number": "1613503",
      "others_can_edit": false,
      "reviewers": "",
      "revision_id": "668025524236855",
      "tags": "",
      "tasks": "",
      "title": "QE_Lib_ae_ig_feed_recs_sourcing_quickbo_relax_media_age_analysis_b2"
    },
    "interpreter": {
      "hash": "f178f7686bb85c5c6e141a85fd4c17c3082d63b89f6cfaecdf98c22c0047a219"
    },
    "kernelspec": {
      "display_name": "Python 3.9.15 ('bope_pca')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "last_base_url": "https://devvm10848.prn0.facebook.com:8090/",
    "last_kernel_id": "33f76217-c3bb-4b3c-be64-89415980d364",
    "last_msg_id": "33163635-cf61d68d283ac2575827f13f_324",
    "last_server_session_id": "e5067c57-e1d5-4267-b323-2335fc1b1e29",
    "outputWidgetContext": {}
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
